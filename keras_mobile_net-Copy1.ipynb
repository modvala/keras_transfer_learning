{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sergei/.local/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/home/sergei/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.mobilenet import MobileNet\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "from keras.applications.mobilenet import preprocess_input\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(img):\n",
    "    \n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_gen_train = ImageDataGenerator(\n",
    "    #featurewise_center=True,\n",
    "    #featurewise_std_normalization=True,\n",
    "    #zca_whitening=True,\n",
    "    rescale=1./255,\n",
    "    rotation_range = 90,\n",
    "    width_shift_range=.5,\n",
    "    height_shift_range=.5,\n",
    "    shear_range=90,\n",
    "    zoom_range= [3, 3],\n",
    "    #channel_shift_range: Float. Range for random channel shifts.\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip= True,\n",
    "    preprocessing_function = preprocess_image\n",
    ")\n",
    "image_gen_val = ImageDataGenerator(\n",
    "    #featurewise_center=True,\n",
    "    #featurewise_std_normalization=True,\n",
    "    #zca_whitening=True,\n",
    "    rescale=1./255,\n",
    "    preprocessing_function = preprocess_image\n",
    ")\n",
    "\n",
    "#training the image preprocessing\n",
    "#image_gen.fit(x_train, augment=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 974865 images belonging to 14951 classes.\n",
      "Found 242443 images belonging to 14951 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = image_gen_train.flow_from_directory(\n",
    "        './input/train_resized_224/train',\n",
    "        target_size=(224, 224),\n",
    "        batch_size=32)\n",
    "\n",
    "validation_generator = image_gen_val.flow_from_directory(\n",
    "        './input/train_resized_224/val',\n",
    "        target_size=(224, 224),\n",
    "        batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from PIL import ImageFile\n",
    "from keras.callbacks import Callback, ModelCheckpoint, TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "es = EarlyStopping( 'val_loss', patience = 5, \n",
    "                        mode = 'min', min_delta = .1)\n",
    "\n",
    "save_check = ModelCheckpoint('./model/model_step_mn_1.h5', monitor='val_loss',\n",
    "                verbose=1, save_best_only=True, save_weights_only=True, mode='auto', period=1)\n",
    "\n",
    "tb = TensorBoard(log_dir='./logs', histogram_freq=0, batch_size=32, \n",
    "                                 write_graph=True, write_grads=False, write_images=False, \n",
    "                                 embeddings_freq=0, embeddings_layer_names=None, embeddings_metadata=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sergei/.local/lib/python3.6/site-packages/keras/applications/mobilenet.py:224: UserWarning: MobileNet shape is undefined. Weights for input shape (224, 224) will be loaded.\n",
      "  warnings.warn('MobileNet shape is undefined.'\n"
     ]
    }
   ],
   "source": [
    "# create the base pre-trained model\n",
    "base_model = MobileNet(weights='imagenet', include_top=False)\n",
    "\n",
    "# add a global spatial average pooling layer\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "# let's add a fully-connected layer\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "# and a logistic layer -- let's say we have 200 classes\n",
    "predictions = Dense(14951, activation='softmax')(x)\n",
    "\n",
    "# this is the model we will train\n",
    "model = Model(inputs=base_model.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49515"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gc import collect\n",
    "collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "500/500 [==============================] - 1392s 3s/step - loss: 7.7871 - val_loss: 7.7950\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 7.79503, saving model to ./model/model_step_mn_1.h5\n",
      "Epoch 2/30\n",
      "500/500 [==============================] - 1343s 3s/step - loss: 7.6843 - val_loss: 7.8813\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 7.79503\n",
      "Epoch 3/30\n",
      "500/500 [==============================] - 1348s 3s/step - loss: 7.6449 - val_loss: 7.8446\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 7.79503\n",
      "Epoch 4/30\n",
      "500/500 [==============================] - 1373s 3s/step - loss: 7.6922 - val_loss: 7.7976\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 7.79503\n",
      "Epoch 5/30\n",
      "500/500 [==============================] - 1362s 3s/step - loss: 7.6866 - val_loss: 7.8160\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 7.79503\n",
      "Epoch 6/30\n",
      "500/500 [==============================] - 1359s 3s/step - loss: 7.6910 - val_loss: 7.7931\n",
      "\n",
      "Epoch 00006: val_loss improved from 7.79503 to 7.79306, saving model to ./model/model_step_mn_1.h5\n",
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# first: train only the top layers (which were randomly initialized)\n",
    "# i.e. freeze all convolutional InceptionV3 layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# compile the model (should be done *after* setting layers to non-trainable)\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
    "\n",
    "class TestCallback(Callback):\n",
    "    def __init__(self, test_data):\n",
    "        self.test_data = test_data\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        x, y = self.test_data\n",
    "        loss, acc = self.model.evaluate(x, y, verbose=0)\n",
    "        print('\\nTesting loss: {}, acc: {}\\n'.format(loss, acc))\n",
    "\n",
    "model.fit_generator(train_generator,\n",
    "                       verbose = 1,\n",
    "                         validation_data=validation_generator, \n",
    "                      callbacks=[save_check, es, tb],\n",
    "                        steps_per_epoch = 500, epochs=30)\n",
    "    \n",
    "    # train the model on the new data for a few epochs\n",
    "    #model.fit_generator(...)\n",
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"./model/model_step_1_mb_end.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"./model/model_step_1_mb_end.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('./model/model_step_mn_1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_check = ModelCheckpoint('./model/model_step_mn_2.h5', monitor='val_loss',\n",
    "                verbose=1, save_best_only=True, save_weights_only=True, mode='auto', period=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 2238773612059792538\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 5482086400\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 11358617874174306947\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1060 with Max-Q Design, pci bus id: 0000:01:00.0, compute capability: 6.1\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/job:localhost/replica:0/task:0/device:GPU:0']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 input_1\n",
      "1 conv1_pad\n",
      "2 conv1\n",
      "3 conv1_bn\n",
      "4 conv1_relu\n",
      "5 conv_pad_1\n",
      "6 conv_dw_1\n",
      "7 conv_dw_1_bn\n",
      "8 conv_dw_1_relu\n",
      "9 conv_pw_1\n",
      "10 conv_pw_1_bn\n",
      "11 conv_pw_1_relu\n",
      "12 conv_pad_2\n",
      "13 conv_dw_2\n",
      "14 conv_dw_2_bn\n",
      "15 conv_dw_2_relu\n",
      "16 conv_pw_2\n",
      "17 conv_pw_2_bn\n",
      "18 conv_pw_2_relu\n",
      "19 conv_pad_3\n",
      "20 conv_dw_3\n",
      "21 conv_dw_3_bn\n",
      "22 conv_dw_3_relu\n",
      "23 conv_pw_3\n",
      "24 conv_pw_3_bn\n",
      "25 conv_pw_3_relu\n",
      "26 conv_pad_4\n",
      "27 conv_dw_4\n",
      "28 conv_dw_4_bn\n",
      "29 conv_dw_4_relu\n",
      "30 conv_pw_4\n",
      "31 conv_pw_4_bn\n",
      "32 conv_pw_4_relu\n",
      "33 conv_pad_5\n",
      "34 conv_dw_5\n",
      "35 conv_dw_5_bn\n",
      "36 conv_dw_5_relu\n",
      "37 conv_pw_5\n",
      "38 conv_pw_5_bn\n",
      "39 conv_pw_5_relu\n",
      "40 conv_pad_6\n",
      "41 conv_dw_6\n",
      "42 conv_dw_6_bn\n",
      "43 conv_dw_6_relu\n",
      "44 conv_pw_6\n",
      "45 conv_pw_6_bn\n",
      "46 conv_pw_6_relu\n",
      "47 conv_pad_7\n",
      "48 conv_dw_7\n",
      "49 conv_dw_7_bn\n",
      "50 conv_dw_7_relu\n",
      "51 conv_pw_7\n",
      "52 conv_pw_7_bn\n",
      "53 conv_pw_7_relu\n",
      "54 conv_pad_8\n",
      "55 conv_dw_8\n",
      "56 conv_dw_8_bn\n",
      "57 conv_dw_8_relu\n",
      "58 conv_pw_8\n",
      "59 conv_pw_8_bn\n",
      "60 conv_pw_8_relu\n",
      "61 conv_pad_9\n",
      "62 conv_dw_9\n",
      "63 conv_dw_9_bn\n",
      "64 conv_dw_9_relu\n",
      "65 conv_pw_9\n",
      "66 conv_pw_9_bn\n",
      "67 conv_pw_9_relu\n",
      "68 conv_pad_10\n",
      "69 conv_dw_10\n",
      "70 conv_dw_10_bn\n",
      "71 conv_dw_10_relu\n",
      "72 conv_pw_10\n",
      "73 conv_pw_10_bn\n",
      "74 conv_pw_10_relu\n",
      "75 conv_pad_11\n",
      "76 conv_dw_11\n",
      "77 conv_dw_11_bn\n",
      "78 conv_dw_11_relu\n",
      "79 conv_pw_11\n",
      "80 conv_pw_11_bn\n",
      "81 conv_pw_11_relu\n",
      "82 conv_pad_12\n",
      "83 conv_dw_12\n",
      "84 conv_dw_12_bn\n",
      "85 conv_dw_12_relu\n",
      "86 conv_pw_12\n",
      "87 conv_pw_12_bn\n",
      "88 conv_pw_12_relu\n",
      "89 conv_pad_13\n",
      "90 conv_dw_13\n",
      "91 conv_dw_13_bn\n",
      "92 conv_dw_13_relu\n",
      "93 conv_pw_13\n",
      "94 conv_pw_13_bn\n",
      "95 conv_pw_13_relu\n"
     ]
    }
   ],
   "source": [
    "# at this point, the top layers are well trained and we can start fine-tuning\n",
    "# convolutional layers from inception V3. We will freeze the bottom N layers\n",
    "# and train the remaining top layers.\n",
    "\n",
    "# let's visualize layer names and layer indices to see how many layers\n",
    "# we should freeze:\n",
    "for i, layer in enumerate(base_model.layers):\n",
    "    print(i, layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "100/100 [==============================] - 16207s 162s/step - loss: 7.6001 - val_loss: 7.7776\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 7.77758, saving model to ./model/model_step_mn_2.h5\n",
      "Epoch 2/20\n",
      "100/100 [==============================] - 1736s 17s/step - loss: 7.6444 - val_loss: 7.8022\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 7.77758\n",
      "Epoch 3/20\n",
      "100/100 [==============================] - 1033s 10s/step - loss: 7.5497 - val_loss: 7.7936\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 7.77758\n",
      "Epoch 4/20\n",
      "100/100 [==============================] - 997s 10s/step - loss: 7.5708 - val_loss: 7.8251\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 7.77758\n",
      "Epoch 5/20\n",
      "100/100 [==============================] - 993s 10s/step - loss: 7.5236 - val_loss: 7.7693\n",
      "\n",
      "Epoch 00005: val_loss improved from 7.77758 to 7.76931, saving model to ./model/model_step_mn_2.h5\n",
      "Epoch 6/20\n",
      "100/100 [==============================] - 968s 10s/step - loss: 7.5944 - val_loss: 7.8041\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 7.76931\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9c493320b8>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we chose to train the top 2 inception blocks, i.e. we will freeze\n",
    "# the first 249 layers and unfreeze the rest:\n",
    "for layer in model.layers[:93]:\n",
    "    layer.trainable = False\n",
    "for layer in model.layers[93:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "# we need to recompile the model for these modifications to take effect\n",
    "# we use SGD with a low learning rate\n",
    "from keras.optimizers import SGD\n",
    "model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss='categorical_crossentropy')\n",
    "\n",
    "model.fit_generator(train_generator,\n",
    "                       verbose = 1,\n",
    "                         validation_data=validation_generator, \n",
    "                      callbacks=[save_check, es, tb],\n",
    "                        steps_per_epoch = 100, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('./model/model_step_mn_2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  ./input/sample_submission.csv.zip\n",
      "  inflating: sample_submission.csv   \n"
     ]
    }
   ],
   "source": [
    "! unzip ./input/sample_submission.csv.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>landmarks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000088da12d664db</td>\n",
       "      <td>8815 0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0001623c6d808702</td>\n",
       "      <td>7249 0.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0001bbb682d45002</td>\n",
       "      <td>5328 0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0002362830cfe3a3</td>\n",
       "      <td>4188 0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000270c9100de789</td>\n",
       "      <td>10506 0.82</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id   landmarks\n",
       "0  000088da12d664db   8815 0.03\n",
       "1  0001623c6d808702   7249 0.61\n",
       "2  0001bbb682d45002    5328 0.5\n",
       "3  0002362830cfe3a3   4188 0.96\n",
       "4  000270c9100de789  10506 0.82"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.read_csv('sample_submission.csv')\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 224, 224, 3)\n",
      "CPU times: user 29.3 ms, sys: 65.3 ms, total: 94.6 ms\n",
      "Wall time: 92.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data = np.array([mpimg.imread('./input/test_resized_224/'+name) for name in os.listdir('./input/test_resized_224/')[:10]], dtype=np.float64)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 loaded\n",
      "10000 loaded\n",
      "10000 loaded\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i in range(submission.shape[0]):\n",
    "    if i % 10000 ==0:\n",
    "        print('10000 loaded')\n",
    "    try:\n",
    "        pil_image = Image.open('./input/test_resized_224/'+submission.iloc[i, 0]+'.jpg')\n",
    "        pil_image = preprocess_image(pil_image)*(1./255)\n",
    "        y_prob = model.predict(pil_image, batch_size=1)\n",
    "        submission.iloc[i, 1] = y_prob.argmax(axis=-1)[0]\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.head(1000).landmarks.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
