{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sergey/.local/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/home/sergey/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "from keras.applications.inception_v3 import preprocess_input\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(img):\n",
    "    \n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_gen_train = ImageDataGenerator(\n",
    "    #featurewise_center=True,\n",
    "    #featurewise_std_normalization=True,\n",
    "    #zca_whitening=True,\n",
    "    rescale=1./255,\n",
    "    rotation_range = 90,\n",
    "    width_shift_range=.5,\n",
    "    height_shift_range=.5,\n",
    "    shear_range=90,\n",
    "    zoom_range= [3, 3],\n",
    "    #channel_shift_range: Float. Range for random channel shifts.\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip= True,\n",
    "    preprocessing_function = preprocess_image\n",
    ")\n",
    "image_gen_val = ImageDataGenerator(\n",
    "    #featurewise_center=True,\n",
    "    #featurewise_std_normalization=True,\n",
    "    #zca_whitening=True,\n",
    "    rescale=1./255,\n",
    "    preprocessing_function = preprocess_image\n",
    ")\n",
    "\n",
    "#training the image preprocessing\n",
    "#image_gen.fit(x_train, augment=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 974865 images belonging to 14951 classes.\n",
      "Found 242443 images belonging to 14951 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = image_gen_train.flow_from_directory(\n",
    "        './input/train_resized_224/train',\n",
    "        target_size=(224, 224),\n",
    "        batch_size=32)\n",
    "\n",
    "validation_generator = image_gen_val.flow_from_directory(\n",
    "        './input/train_resized_224/val',\n",
    "        target_size=(224, 224),\n",
    "        batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from PIL import ImageFile\n",
    "from keras.callbacks import Callback, ModelCheckpoint, TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_img(address, size):\n",
    "    \"\"\"Read and resize image.\n",
    "    Returns Image as numpy array, by normalizing the values\n",
    "    \"\"\"\n",
    "    img = image.load_img(address, target_size=size)\n",
    "    img = image.img_to_array(img)\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>source</th>\n",
       "      <th>landmark_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cacf8152e2d2ae60</td>\n",
       "      <td>http://static.panoramio.com/photos/original/70...</td>\n",
       "      <td>4676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0a58358a2afd3e4e</td>\n",
       "      <td>http://lh6.ggpht.com/-igpT6wu0mIA/ROV8HnUuABI/...</td>\n",
       "      <td>6651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6b2bb500b6a38aa0</td>\n",
       "      <td>http://lh6.ggpht.com/-vKr5G5MEusk/SR6r6SJi6mI/...</td>\n",
       "      <td>11284</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                             source  \\\n",
       "0  cacf8152e2d2ae60  http://static.panoramio.com/photos/original/70...   \n",
       "1  0a58358a2afd3e4e  http://lh6.ggpht.com/-igpT6wu0mIA/ROV8HnUuABI/...   \n",
       "2  6b2bb500b6a38aa0  http://lh6.ggpht.com/-vKr5G5MEusk/SR6r6SJi6mI/...   \n",
       "\n",
       "   landmark_id  \n",
       "0         4676  \n",
       "1         6651  \n",
       "2        11284  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('./input/train.csv', skiprows=1, nrows=3, names = ['id', 'source', 'landmark_id'])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SIZE = 224\n",
    "\n",
    "#POOLING = 'avg'\n",
    "def load_image(skip, nrows):\n",
    "    data = pd.read_csv('./input/train.csv', skiprows=skip, nrows=nrows, names = ['id', 'source', 'landmark_id'])\n",
    "    labels = data.shape[0]\n",
    "    ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "    x_train = np.zeros((labels, INPUT_SIZE, INPUT_SIZE, 3), dtype='float32')\n",
    "    y_train= np.zeros((labels,), dtype='float32')\n",
    "    for i, img_id in tqdm(enumerate(data['id'])):\n",
    "        try:\n",
    "            img = read_img('./input/train_resized_224/'+img_id+'.jpg', (INPUT_SIZE, INPUT_SIZE))\n",
    "            x = preprocess_input(np.expand_dims(img.copy(), axis=0))\n",
    "            x_train[i] = x\n",
    "            y_train[i]=int(data['landmark_id'][i])\n",
    "        except:\n",
    "            continue \n",
    "    return x_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneHotEncoder(categorical_features='all', dtype=<class 'numpy.float64'>,\n",
       "       handle_unknown='error', n_values='auto', sparse=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder(sparse=False)\n",
    "data = pd.read_csv('./input/train.csv')\n",
    "data = data.groupby(['landmark_id']).head(20)\n",
    "labels = data.landmark_id.nunique()\n",
    "enc.fit(data['landmark_id'].astype(int).values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "es = EarlyStopping( 'val_loss', patience = 5, \n",
    "                        mode = 'min', min_delta = .1)\n",
    "\n",
    "save_check = ModelCheckpoint('./model/model_step_1.h5', monitor='val_loss',\n",
    "                verbose=1, save_best_only=True, save_weights_only=True, mode='auto', period=1)\n",
    "\n",
    "tb = TensorBoard(log_dir='./logs', histogram_freq=0, batch_size=32, \n",
    "                                 write_graph=True, write_grads=False, write_images=False, \n",
    "                                 embeddings_freq=0, embeddings_layer_names=None, embeddings_metadata=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the base pre-trained model\n",
    "base_model = InceptionV3(weights='imagenet', include_top=False)\n",
    "\n",
    "# add a global spatial average pooling layer\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "# let's add a fully-connected layer\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "# and a logistic layer -- let's say we have 200 classes\n",
    "predictions = Dense(14951, activation='softmax')(x)\n",
    "\n",
    "# this is the model we will train\n",
    "model = Model(inputs=base_model.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "166065"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gc import collect\n",
    "collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "200/200 [==============================] - 9833s 49s/step - loss: 8.3441 - val_loss: 8.5200\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 8.52005, saving model to ./model/model_step_1.h5\n",
      "Epoch 2/30\n",
      "200/200 [==============================] - 1423s 7s/step - loss: 7.9744 - val_loss: 8.1336\n",
      "\n",
      "Epoch 00002: val_loss improved from 8.52005 to 8.13357, saving model to ./model/model_step_1.h5\n",
      "Epoch 3/30\n",
      "200/200 [==============================] - 1286s 6s/step - loss: 7.9080 - val_loss: 8.2842\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 8.13357\n",
      "Epoch 4/30\n",
      "200/200 [==============================] - 1314s 7s/step - loss: 7.8590 - val_loss: 8.1075\n",
      "\n",
      "Epoch 00004: val_loss improved from 8.13357 to 8.10752, saving model to ./model/model_step_1.h5\n",
      "Epoch 5/30\n",
      "200/200 [==============================] - 1310s 7s/step - loss: 7.8292 - val_loss: 8.0795\n",
      "\n",
      "Epoch 00005: val_loss improved from 8.10752 to 8.07947, saving model to ./model/model_step_1.h5\n",
      "Epoch 6/30\n",
      "200/200 [==============================] - 1304s 7s/step - loss: 7.7375 - val_loss: 8.0846\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 8.07947\n",
      "Epoch 7/30\n",
      "200/200 [==============================] - 1301s 7s/step - loss: 7.7370 - val_loss: 8.0687\n",
      "\n",
      "Epoch 00007: val_loss improved from 8.07947 to 8.06871, saving model to ./model/model_step_1.h5\n",
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# first: train only the top layers (which were randomly initialized)\n",
    "# i.e. freeze all convolutional InceptionV3 layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# compile the model (should be done *after* setting layers to non-trainable)\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
    "\n",
    "class TestCallback(Callback):\n",
    "    def __init__(self, test_data):\n",
    "        self.test_data = test_data\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        x, y = self.test_data\n",
    "        loss, acc = self.model.evaluate(x, y, verbose=0)\n",
    "        print('\\nTesting loss: {}, acc: {}\\n'.format(loss, acc))\n",
    "\n",
    "model.fit_generator(train_generator,\n",
    "                       verbose = 1,\n",
    "                         validation_data=validation_generator, \n",
    "                      callbacks=[save_check, es, tb],\n",
    "                        steps_per_epoch = 200, epochs=30)\n",
    "    \n",
    "    # train the model on the new data for a few epochs\n",
    "    #model.fit_generator(...)\n",
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"./model/model_step_1_end.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"./model/model_step_1_end.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('./model/model_step_1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_check = ModelCheckpoint('./model/model_step_2.h5', monitor='val_loss',\n",
    "                verbose=1, save_best_only=True, save_weights_only=True, mode='auto', period=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 13560514697701658143\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 5555093504\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 12917793432077805929\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1060 with Max-Q Design, pci bus id: 0000:01:00.0, compute capability: 6.1\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/job:localhost/replica:0/task:0/device:GPU:0']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "100/100 [==============================] - 3677s 37s/step - loss: 7.8019 - val_loss: 7.9109\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 7.91091, saving model to ./model/model_step_2.h5\n",
      "Epoch 2/3\n",
      "100/100 [==============================] - 1243s 12s/step - loss: 7.7291 - val_loss: 7.8945\n",
      "\n",
      "Epoch 00002: val_loss improved from 7.91091 to 7.89448, saving model to ./model/model_step_2.h5\n",
      "Epoch 3/3\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 7.6421"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/sergey/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-14-f8a20cc07094>\", line 26, in <module>\n",
      "    steps_per_epoch = 100, epochs=3)\n",
      "  File \"/home/sergey/.local/lib/python3.6/site-packages/keras/legacy/interfaces.py\", line 91, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/sergey/.local/lib/python3.6/site-packages/keras/engine/training.py\", line 2250, in fit_generator\n",
      "    max_queue_size=max_queue_size)\n",
      "  File \"/home/sergey/.local/lib/python3.6/site-packages/keras/legacy/interfaces.py\", line 91, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/sergey/.local/lib/python3.6/site-packages/keras/engine/training.py\", line 2399, in evaluate_generator\n",
      "    outs = self.test_on_batch(x, y, sample_weight=sample_weight)\n",
      "  File \"/home/sergey/.local/lib/python3.6/site-packages/keras/engine/training.py\", line 1924, in test_on_batch\n",
      "    outputs = self.test_function(ins)\n",
      "  File \"/home/sergey/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\", line 2482, in __call__\n",
      "    **self.session_kwargs)\n",
      "  File \"/home/sergey/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 900, in run\n",
      "    run_metadata_ptr)\n",
      "  File \"/home/sergey/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1135, in _run\n",
      "    feed_dict_tensor, options, run_metadata)\n",
      "  File \"/home/sergey/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1316, in _do_run\n",
      "    run_metadata)\n",
      "  File \"/home/sergey/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1322, in _do_call\n",
      "    return fn(*args)\n",
      "  File \"/home/sergey/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1307, in _run_fn\n",
      "    options, feed_dict, fetch_list, target_list, run_metadata)\n",
      "  File \"/home/sergey/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1409, in _call_tf_sessionrun\n",
      "    run_metadata)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/sergey/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 1828, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/sergey/anaconda3/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1090, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/sergey/anaconda3/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 311, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/sergey/anaconda3/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 345, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/home/sergey/anaconda3/lib/python3.6/inspect.py\", line 1483, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/home/sergey/anaconda3/lib/python3.6/inspect.py\", line 1445, in getframeinfo\n",
      "    lines, lnum = findsource(frame)\n",
      "  File \"/home/sergey/anaconda3/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 177, in findsource\n",
      "    lines = linecache.getlines(file, globals_dict)\n",
      "  File \"/home/sergey/anaconda3/lib/python3.6/linecache.py\", line 47, in getlines\n",
      "    return updatecache(filename, module_globals)\n",
      "  File \"/home/sergey/anaconda3/lib/python3.6/linecache.py\", line 136, in updatecache\n",
      "    with tokenize.open(fullname) as fp:\n",
      "  File \"/home/sergey/anaconda3/lib/python3.6/tokenize.py\", line 454, in open\n",
      "    encoding, lines = detect_encoding(buffer.readline)\n",
      "  File \"/home/sergey/anaconda3/lib/python3.6/tokenize.py\", line 423, in detect_encoding\n",
      "    first = read_or_stop()\n",
      "  File \"/home/sergey/anaconda3/lib/python3.6/tokenize.py\", line 381, in read_or_stop\n",
      "    return readline()\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:tornado.general:Uncaught exception, closing connection.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/sergey/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n",
      "    callback(*args, **kwargs)\n",
      "  File \"/home/sergey/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/sergey/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n",
      "    return self.dispatch_shell(stream, msg)\n",
      "  File \"/home/sergey/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n",
      "    handler(stream, idents, msg)\n",
      "  File \"/home/sergey/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 421, in execute_request\n",
      "    self._abort_queues()\n",
      "  File \"/home/sergey/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 636, in _abort_queues\n",
      "    self._abort_queue(stream)\n",
      "  File \"/home/sergey/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 661, in _abort_queue\n",
      "    poller.poll(50)\n",
      "  File \"/home/sergey/anaconda3/lib/python3.6/site-packages/zmq/sugar/poll.py\", line 99, in poll\n",
      "    return zmq_poll(self.sockets, timeout=timeout)\n",
      "  File \"zmq/backend/cython/_poll.pyx\", line 116, in zmq.backend.cython._poll.zmq_poll\n",
      "  File \"zmq/backend/cython/checkrc.pxd\", line 12, in zmq.backend.cython.checkrc._check_rc\n",
      "KeyboardInterrupt\n",
      "ERROR:tornado.general:Uncaught exception, closing connection.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/sergey/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n",
      "    self._handle_recv()\n",
      "  File \"/home/sergey/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n",
      "    self._run_callback(callback, msg)\n",
      "  File \"/home/sergey/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n",
      "    callback(*args, **kwargs)\n",
      "  File \"/home/sergey/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/sergey/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n",
      "    return self.dispatch_shell(stream, msg)\n",
      "  File \"/home/sergey/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n",
      "    handler(stream, idents, msg)\n",
      "  File \"/home/sergey/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 421, in execute_request\n",
      "    self._abort_queues()\n",
      "  File \"/home/sergey/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 636, in _abort_queues\n",
      "    self._abort_queue(stream)\n",
      "  File \"/home/sergey/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 661, in _abort_queue\n",
      "    poller.poll(50)\n",
      "  File \"/home/sergey/anaconda3/lib/python3.6/site-packages/zmq/sugar/poll.py\", line 99, in poll\n",
      "    return zmq_poll(self.sockets, timeout=timeout)\n",
      "  File \"zmq/backend/cython/_poll.pyx\", line 116, in zmq.backend.cython._poll.zmq_poll\n",
      "  File \"zmq/backend/cython/checkrc.pxd\", line 12, in zmq.backend.cython.checkrc._check_rc\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "# at this point, the top layers are well trained and we can start fine-tuning\n",
    "# convolutional layers from inception V3. We will freeze the bottom N layers\n",
    "# and train the remaining top layers.\n",
    "\n",
    "# let's visualize layer names and layer indices to see how many layers\n",
    "# we should freeze:\n",
    "#for i, layer in enumerate(base_model.layers):\n",
    "    #print(i, layer.name)\n",
    "\n",
    "# we chose to train the top 2 inception blocks, i.e. we will freeze\n",
    "# the first 249 layers and unfreeze the rest:\n",
    "for layer in model.layers[:249]:\n",
    "    layer.trainable = False\n",
    "for layer in model.layers[249:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "# we need to recompile the model for these modifications to take effect\n",
    "# we use SGD with a low learning rate\n",
    "from keras.optimizers import SGD\n",
    "model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss='categorical_crossentropy')\n",
    "\n",
    "model.fit_generator(train_generator,\n",
    "                       verbose = 1,\n",
    "                         validation_data=validation_generator, \n",
    "                      callbacks=[save_check, es, tb],\n",
    "                        steps_per_epoch = 100, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
